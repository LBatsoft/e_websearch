"""
Search Agent è§„åˆ’å™¨ç»„ä»¶

è´Ÿè´£åˆ†ææŸ¥è¯¢ã€åˆ†è§£ä»»åŠ¡ã€ç”Ÿæˆæ‰§è¡Œç­–ç•¥
"""

import re
import uuid
from typing import Dict, List, Optional, Tuple
from loguru import logger

from ..llm_enhancer import LLMEnhancer
from ..models import SourceType
from .models import (
    AgentSearchRequest,
    ExecutionPlan,
    ExecutionStep,
    StepType,
    PlanningStrategy,
    ExecutionStatus,
)
# from .dynamic_planner import DynamicStepGenerator  # TODO: å®ç°åŠ¨æ€è§„åˆ’å™¨


class QueryAnalyzer:
    """æŸ¥è¯¢åˆ†æå™¨ - åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾å’Œå¤æ‚åº¦"""
    
    def __init__(self, llm_enhancer: Optional[LLMEnhancer] = None):
        self.llm_enhancer = llm_enhancer
        
        # é¢„å®šä¹‰çš„æŸ¥è¯¢æ¨¡å¼
        self.patterns = {
            "comparison": [r"å¯¹æ¯”|æ¯”è¾ƒ|vs|versus|åŒºåˆ«|å·®å¼‚"],
            "tutorial": [r"æ•™ç¨‹|å¦‚ä½•|æ€ä¹ˆ|æ­¥éª¤|æ–¹æ³•"],
            "definition": [r"ä»€ä¹ˆæ˜¯|å®šä¹‰|å«ä¹‰|æ¦‚å¿µ"],
            "latest": [r"æœ€æ–°|æœ€è¿‘|2024|2023|ä»Šå¹´|æœ€æ–°æ¶ˆæ¯"],
            "deep_dive": [r"è¯¦ç»†|æ·±å…¥|å…¨é¢|å®Œæ•´|ç³»ç»Ÿ"],
            "multi_aspect": [r"å’Œ|ä¸|ä»¥åŠ|è¿˜æœ‰|åŒ…æ‹¬"],
        }
    
    async def analyze_query(self, query: str) -> Dict[str, any]:
        """åˆ†ææŸ¥è¯¢ï¼Œè¿”å›åˆ†æç»“æœ"""
        analysis = {
            "original_query": query,
            "query_type": self._classify_query_type(query),
            "complexity": self._assess_complexity(query),
            "entities": self._extract_entities(query),
            "intent": self._infer_intent(query),
            "requires_multiple_searches": self._needs_multiple_searches(query),
            "suggested_refinements": self._suggest_refinements(query),
        }
        
        # å¦‚æœæœ‰ LLM å¢å¼ºï¼Œä½¿ç”¨ LLM è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æ
        if self.llm_enhancer and self.llm_enhancer.is_available():
            try:
                llm_analysis = await self._llm_analyze_query(query)
                analysis.update(llm_analysis)
            except Exception as e:
                logger.warning(f"LLM æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
        
        logger.info(f"æŸ¥è¯¢åˆ†æå®Œæˆ: {query} -> {analysis['query_type']}, å¤æ‚åº¦: {analysis['complexity']}")
        return analysis
    
    def _classify_query_type(self, query: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        query_lower = query.lower()
        
        for query_type, patterns in self.patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    return query_type
        
        return "general"
    
    def _assess_complexity(self, query: str) -> str:
        """è¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦"""
        # åŸºäºæŸ¥è¯¢é•¿åº¦ã€å…³é”®è¯æ•°é‡ã€ç‰¹æ®Šæ¨¡å¼ç­‰è¯„ä¼°
        words = query.split()
        
        if len(words) <= 2:
            return "simple"
        elif len(words) <= 5:
            return "medium"
        else:
            return "complex"
    
    def _extract_entities(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢ä¸­çš„å®ä½“"""
        # ç®€å•çš„å®ä½“æå–ï¼Œå¯ä»¥åç»­ç”¨ NER æ¨¡å‹å¢å¼º
        words = query.split()
        entities = []
        
        # æå–å¯èƒ½çš„å®ä½“ï¼ˆå¤§å†™å¼€å¤´çš„è¯ã€ä¸“ä¸šæœ¯è¯­ç­‰ï¼‰
        for word in words:
            if word[0].isupper() and len(word) > 1:
                entities.append(word)
        
        return entities
    
    def _infer_intent(self, query: str) -> str:
        """æ¨æ–­æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["å¦‚ä½•", "æ€ä¹ˆ", "æ–¹æ³•"]):
            return "how_to"
        elif any(word in query_lower for word in ["ä»€ä¹ˆæ˜¯", "å®šä¹‰", "å«ä¹‰"]):
            return "definition"
        elif any(word in query_lower for word in ["æœ€æ–°", "æœ€è¿‘", "æ–°é—»"]):
            return "latest_info"
        elif any(word in query_lower for word in ["å¯¹æ¯”", "æ¯”è¾ƒ", "åŒºåˆ«"]):
            return "comparison"
        else:
            return "information_seeking"
    
    def _needs_multiple_searches(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¤šæ¬¡æœç´¢"""
        # åŸºäºæŸ¥è¯¢å¤æ‚åº¦å’Œç±»å‹åˆ¤æ–­
        complexity = self._assess_complexity(query)
        query_type = self._classify_query_type(query)
        
        return (
            complexity in ["medium", "complex"] or
            query_type in ["comparison", "deep_dive", "multi_aspect"]
        )
    
    def _suggest_refinements(self, query: str) -> List[str]:
        """å»ºè®®æŸ¥è¯¢ä¼˜åŒ–"""
        refinements = []
        query_type = self._classify_query_type(query)
        
        if query_type == "comparison":
            refinements.extend([
                f"{query} ä¼˜ç¼ºç‚¹",
                f"{query} è¯¦ç»†å¯¹æ¯”",
                f"{query} é€‰æ‹©å»ºè®®"
            ])
        elif query_type == "tutorial":
            refinements.extend([
                f"{query} è¯¦ç»†æ­¥éª¤",
                f"{query} å®ä¾‹",
                f"{query} æ³¨æ„äº‹é¡¹"
            ])
        elif query_type == "latest":
            refinements.extend([
                f"{query} 2024",
                f"{query} æœ€æ–°å‘å±•",
                f"{query} è¶‹åŠ¿åˆ†æ"
            ])
        
        return refinements[:3]  # æœ€å¤šè¿”å›3ä¸ªå»ºè®®
    
    async def _llm_analyze_query(self, query: str) -> Dict[str, any]:
        """ä½¿ç”¨ LLM è¿›è¡ŒæŸ¥è¯¢åˆ†æ"""
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹æœç´¢æŸ¥è¯¢ï¼Œè¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
        
        æŸ¥è¯¢: {query}
        
        è¯·åˆ†æï¼š
        1. æŸ¥è¯¢çš„ä¸»è¦æ„å›¾
        2. æ˜¯å¦éœ€è¦å¤šæ­¥éª¤æœç´¢
        3. å»ºè®®çš„æœç´¢ç­–ç•¥
        4. å¯èƒ½çš„å­æŸ¥è¯¢
        
        è¿”å›æ ¼å¼ï¼š
        {{
            "main_intent": "ä¸»è¦æ„å›¾æè¿°",
            "needs_multi_step": true/false,
            "suggested_strategy": "å»ºè®®çš„æœç´¢ç­–ç•¥",
            "sub_queries": ["å­æŸ¥è¯¢1", "å­æŸ¥è¯¢2"]
        }}
        """
        
        try:
            response = await self.llm_enhancer._select_provider().generate(
                [{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            if response:
                import json
                return json.loads(response)
        except Exception as e:
            logger.debug(f"LLM æŸ¥è¯¢åˆ†æè§£æå¤±è´¥: {e}")
        
        return {}


class TaskDecomposer:
    """ä»»åŠ¡åˆ†è§£å™¨ - å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡"""
    
    def __init__(self, query_analyzer: QueryAnalyzer, llm_enhancer: Optional[LLMEnhancer] = None):
        self.query_analyzer = query_analyzer
        self.dynamic_generator = None  # TODO: å®ç°åŠ¨æ€è§„åˆ’å™¨
        # self.dynamic_generator = DynamicStepGenerator(llm_enhancer)
        self.use_dynamic_generation = True  # é»˜è®¤ä½¿ç”¨åŠ¨æ€ç”Ÿæˆ
    
    async def decompose_task(self, request: AgentSearchRequest, 
                           analysis) -> List[ExecutionStep]:
        """åˆ†è§£ä»»åŠ¡ä¸ºæ‰§è¡Œæ­¥éª¤"""
        steps = []
        
        try:
            # æ ‡å‡†åŒ–åˆ†æç»“æœ
            normalized_analysis = self._normalize_analysis_result(analysis)
            
            logger.debug(f"æ ‡å‡†åŒ–åˆ†æç»“æœ: {normalized_analysis}")
            
            if not normalized_analysis["requires_multiple_searches"]:
                # ç®€å•æŸ¥è¯¢ï¼Œå•æ­¥æ‰§è¡Œ
                if self.use_dynamic_generation:
                    # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆå™¨ï¼Œå³ä½¿æ˜¯ç®€å•æŸ¥è¯¢ä¹Ÿå¯èƒ½ç”Ÿæˆå¤šä¸ªä¼˜åŒ–æ­¥éª¤
                    # TODO: å®ç°åŠ¨æ€è§„åˆ’å™¨
                    # steps.extend(await self.dynamic_generator.generate_steps(request, normalized_analysis))
                    pass
                    logger.info(f"âœ… åŠ¨æ€ç”Ÿæˆç®€å•æ‰§è¡Œè®¡åˆ’: {len(steps)}ä¸ªæ­¥éª¤")
                else:
                    # ä¼ ç»Ÿæ–¹å¼
                    steps.append(self._create_simple_search_step(request, normalized_analysis))
                    logger.info(f"âœ… åˆ›å»ºç®€å•æ‰§è¡Œè®¡åˆ’: 1ä¸ªæ­¥éª¤")
            else:
                # å¤æ‚æŸ¥è¯¢ï¼Œå¤šæ­¥æ‰§è¡Œ
                if self.use_dynamic_generation:
                    # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆå™¨
                    # TODO: å®ç°åŠ¨æ€è§„åˆ’å™¨
                    # steps.extend(await self.dynamic_generator.generate_steps(request, normalized_analysis))
                    pass
                    logger.info(f"âœ… åŠ¨æ€ç”Ÿæˆå¤šæ­¥æ‰§è¡Œè®¡åˆ’: {len(steps)}ä¸ªæ­¥éª¤")
                else:
                    # ä¼ ç»Ÿç¡¬ç¼–ç æ–¹å¼ï¼ˆä¿ç•™ä½œä¸ºå›é€€ï¼‰
                    steps.extend(await self._create_multi_step_plan(request, normalized_analysis))
                    logger.info(f"âœ… åˆ›å»ºå¤šæ­¥æ‰§è¡Œè®¡åˆ’: {len(steps)}ä¸ªæ­¥éª¤")
            
            # éªŒè¯æ­¥éª¤
            if not steps:
                logger.warning("âš ï¸ ä»»åŠ¡åˆ†è§£ç»“æœä¸ºç©ºï¼Œåˆ›å»ºé»˜è®¤æ­¥éª¤")
                steps.append(self._create_simple_search_step(request, normalized_analysis))
            
            return steps
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡åˆ†è§£å¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤çš„ç®€å•æœç´¢æ­¥éª¤
            return [self._create_simple_search_step(request, {})]
    
    def _normalize_analysis_result(self, analysis) -> Dict[str, any]:
        """æ ‡å‡†åŒ–ä¸åŒç±»å‹çš„åˆ†æç»“æœ"""
        if hasattr(analysis, 'requires_multiple_searches'):
            # é«˜çº§åˆ†æå™¨ç»“æœï¼ˆå¯¹è±¡ç±»å‹ï¼‰
            return {
                "requires_multiple_searches": analysis.requires_multiple_searches,
                "query_type": analysis.query_type,
                "complexity": analysis.complexity,
                "intent": analysis.intent,
                "entities": getattr(analysis, 'entities', []),
                "keywords": getattr(analysis, 'keywords', []),
                "suggested_refinements": analysis.suggested_refinements or [],
                "confidence_scores": getattr(analysis, 'confidence_scores', {})
            }
        else:
            # åŸºç¡€åˆ†æå™¨ç»“æœï¼ˆå­—å…¸ç±»å‹ï¼‰
            return {
                "requires_multiple_searches": analysis.get("requires_multiple_searches", False),
                "query_type": analysis.get("query_type", "general"),
                "complexity": analysis.get("complexity", "simple"),
                "intent": analysis.get("intent", "information_seeking"),
                "entities": analysis.get("entities", []),
                "keywords": analysis.get("keywords", []),
                "suggested_refinements": analysis.get("suggested_refinements", []),
                "confidence_scores": {}
            }
    
    def _create_simple_search_step(self, request: AgentSearchRequest, 
                                 analysis: Dict[str, any]) -> ExecutionStep:
        """åˆ›å»ºç®€å•æœç´¢æ­¥éª¤"""
        return ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"æœç´¢: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={
                "is_primary_search": True,
                "query_type": analysis.get("query_type", "general"),
                "complexity": analysis.get("complexity", "simple"),
            }
        )
    
    async def _create_multi_step_plan(self, request: AgentSearchRequest, 
                                    analysis: Dict[str, any]) -> List[ExecutionStep]:
        """åˆ›å»ºå¤šæ­¥æ‰§è¡Œè®¡åˆ’"""
        steps = []
        query_type = analysis.get("query_type", "general")
        
        if query_type == "comparison":
            steps.extend(self._create_comparison_steps(request, analysis))
        elif query_type == "deep_dive":
            steps.extend(self._create_deep_dive_steps(request, analysis))
        elif query_type == "tutorial":
            steps.extend(self._create_tutorial_steps(request, analysis))
        else:
            steps.extend(self._create_general_multi_steps(request, analysis))
        
        return steps
    
    def _create_comparison_steps(self, request: AgentSearchRequest, 
                               analysis: Dict[str, any]) -> List[ExecutionStep]:
        """åˆ›å»ºå¯¹æ¯”ç±»æŸ¥è¯¢çš„æ­¥éª¤"""
        steps = []
        
        # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€æœç´¢
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"åŸºç¡€æœç´¢: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "baseline_search"}
        ))
        
        # ç¬¬äºŒæ­¥ï¼šæ·±å…¥å¯¹æ¯”
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"æ·±å…¥å¯¹æ¯”: {request.query} è¯¦ç»†å¯¹æ¯”",
            query=f"{request.query} è¯¦ç»†å¯¹æ¯” ä¼˜ç¼ºç‚¹",
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "detailed_comparison"}
        ))
        
        # ç¬¬ä¸‰æ­¥ï¼šæ€»ç»“åˆ†æ
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.ANALYZE,
            description="åˆ†æå¯¹æ¯”ç»“æœ",
            query=request.query,
            sources=[],
            max_results=0,
            metadata={"step_purpose": "comparison_analysis"}
        ))
        
        return steps
    
    def _create_deep_dive_steps(self, request: AgentSearchRequest, 
                              analysis: Dict[str, any]) -> List[ExecutionStep]:
        """åˆ›å»ºæ·±åº¦æŒ–æ˜ç±»æŸ¥è¯¢çš„æ­¥éª¤"""
        steps = []
        
        # ç¬¬ä¸€æ­¥ï¼šæ¦‚è§ˆæœç´¢
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"æ¦‚è§ˆæœç´¢: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "overview_search"}
        ))
        
        # ç¬¬äºŒæ­¥ï¼šè¯¦ç»†ä¿¡æ¯
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"è¯¦ç»†ä¿¡æ¯: {request.query} è¯¦ç»†ä»‹ç»",
            query=f"{request.query} è¯¦ç»†ä»‹ç» æ·±å…¥åˆ†æ",
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "detailed_search"}
        ))
        
        # ç¬¬ä¸‰æ­¥ï¼šç›¸å…³åº”ç”¨
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"ç›¸å…³åº”ç”¨: {request.query} åº”ç”¨æ¡ˆä¾‹",
            query=f"{request.query} åº”ç”¨æ¡ˆä¾‹ å®é™…ä½¿ç”¨",
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "application_search"}
        ))
        
        return steps
    
    def _create_tutorial_steps(self, request: AgentSearchRequest, 
                             analysis: Dict[str, any]) -> List[ExecutionStep]:
        """åˆ›å»ºæ•™ç¨‹ç±»æŸ¥è¯¢çš„æ­¥éª¤"""
        steps = []
        
        # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€æ•™ç¨‹
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"åŸºç¡€æ•™ç¨‹: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "basic_tutorial"}
        ))
        
        # ç¬¬äºŒæ­¥ï¼šè¯¦ç»†æ­¥éª¤
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"è¯¦ç»†æ­¥éª¤: {request.query} è¯¦ç»†æ­¥éª¤",
            query=f"{request.query} è¯¦ç»†æ­¥éª¤ å…·ä½“æ–¹æ³•",
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "detailed_steps"}
        ))
        
        # ç¬¬ä¸‰æ­¥ï¼šæ³¨æ„äº‹é¡¹
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"æ³¨æ„äº‹é¡¹: {request.query} æ³¨æ„äº‹é¡¹",
            query=f"{request.query} æ³¨æ„äº‹é¡¹ å¸¸è§é—®é¢˜",
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "precautions"}
        ))
        
        return steps
    
    def _create_general_multi_steps(self, request: AgentSearchRequest, 
                                  analysis: Dict[str, any]) -> List[ExecutionStep]:
        """åˆ›å»ºé€šç”¨å¤šæ­¥æŸ¥è¯¢"""
        steps = []
        
        # ç¬¬ä¸€æ­¥ï¼šä¸»è¦æœç´¢
        steps.append(ExecutionStep(
            step_id=f"step_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"ä¸»è¦æœç´¢: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"step_purpose": "primary_search"}
        ))
        
        # ç¬¬äºŒæ­¥ï¼šè¡¥å……æœç´¢
        refinements = analysis.get("suggested_refinements", [])
        if refinements:
            steps.append(ExecutionStep(
                step_id=f"step_{uuid.uuid4().hex[:8]}",
                step_type=StepType.SEARCH,
                description=f"è¡¥å……æœç´¢: {refinements[0]}",
                query=refinements[0],
                sources=request.sources,
                max_results=request.max_results_per_iteration,
                metadata={"step_purpose": "supplementary_search"}
            ))
        
        return steps


class StrategyGenerator:
    """ç­–ç•¥ç”Ÿæˆå™¨ - æ ¹æ®åˆ†æç»“æœç”Ÿæˆæ‰§è¡Œç­–ç•¥"""
    
    def __init__(self):
        # ç­–ç•¥é€‰æ‹©æƒé‡é…ç½®
        self.strategy_weights = {
            PlanningStrategy.SIMPLE: {
                "simple": 0.8, "medium": 0.3, "complex": 0.1,
                "general": 0.7, "definition": 0.8, "tutorial": 0.6,
                "comparison": 0.2, "deep_dive": 0.1
            },
            PlanningStrategy.ITERATIVE: {
                "simple": 0.1, "medium": 0.6, "complex": 0.7,
                "general": 0.2, "definition": 0.1, "tutorial": 0.7,
                "comparison": 0.8, "deep_dive": 0.9
            },
            PlanningStrategy.PARALLEL: {
                "simple": 0.1, "medium": 0.1, "complex": 0.2,
                "general": 0.1, "definition": 0.1, "tutorial": 0.1,
                "comparison": 0.0, "deep_dive": 0.0
            }
        }
    
    def generate_strategy(self, request: AgentSearchRequest, 
                         analysis) -> PlanningStrategy:
        """ç”Ÿæˆæ‰§è¡Œç­–ç•¥"""
        # æ ‡å‡†åŒ–åˆ†æç»“æœ
        if hasattr(analysis, 'complexity'):
            complexity = analysis.complexity
            query_type = analysis.query_type
            needs_multiple = analysis.requires_multiple_searches
            confidence_scores = getattr(analysis, 'confidence_scores', {})
        else:
            complexity = analysis.get("complexity", "simple")
            query_type = analysis.get("query_type", "general")
            needs_multiple = analysis.get("requires_multiple_searches", False)
            confidence_scores = analysis.get("confidence_scores", {})
        
        # æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„ç­–ç•¥
        if request.planning_strategy != PlanningStrategy.ADAPTIVE:
            logger.info(f"ğŸ¯ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šç­–ç•¥: {request.planning_strategy.value}")
            return request.planning_strategy
        
        # æ™ºèƒ½è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©
        strategy = self._select_adaptive_strategy(
            complexity, query_type, needs_multiple, confidence_scores
        )
        
        logger.info(f"ğŸ¤– è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©: {strategy.value} (å¤æ‚åº¦: {complexity}, ç±»å‹: {query_type})")
        return strategy
    
    def _select_adaptive_strategy(self, complexity: str, query_type: str, 
                                needs_multiple: bool, confidence_scores: Dict) -> PlanningStrategy:
        """æ™ºèƒ½é€‰æ‹©è‡ªé€‚åº”ç­–ç•¥"""
        
        # è®¡ç®—æ¯ç§ç­–ç•¥çš„å¾—åˆ†
        strategy_scores = {}
        
        for strategy in PlanningStrategy:
            if strategy == PlanningStrategy.ADAPTIVE:
                continue
                
            score = 0.0
            weights = self.strategy_weights.get(strategy, {})
            
            # å¤æ‚åº¦æƒé‡
            score += weights.get(complexity, 0.0) * 0.4
            
            # æŸ¥è¯¢ç±»å‹æƒé‡
            score += weights.get(query_type, 0.0) * 0.3
            
            # å¤šæ­¥éœ€æ±‚æƒé‡
            if needs_multiple:
                if strategy == PlanningStrategy.SIMPLE:
                    score -= 0.2
                else:
                    score += 0.2
            else:
                if strategy == PlanningStrategy.SIMPLE:
                    score += 0.1
            
            # ç½®ä¿¡åº¦æƒé‡
            if confidence_scores:
                avg_confidence = sum(confidence_scores.values()) / len(confidence_scores)
                if avg_confidence > 0.7:
                    # é«˜ç½®ä¿¡åº¦æ—¶åå‘ç®€å•ç­–ç•¥
                    if strategy == PlanningStrategy.SIMPLE:
                        score += 0.1
                elif avg_confidence < 0.5:
                    # ä½ç½®ä¿¡åº¦æ—¶åå‘è¿­ä»£ç­–ç•¥
                    if strategy == PlanningStrategy.ITERATIVE:
                        score += 0.1
            
            strategy_scores[strategy] = score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç­–ç•¥
        best_strategy = max(strategy_scores.items(), key=lambda x: x[1])[0]
        
        logger.debug(f"ç­–ç•¥å¾—åˆ†: {[(s.value, round(score, 3)) for s, score in strategy_scores.items()]}")
        
        return best_strategy


class SearchPlanner:
    """æœç´¢è§„åˆ’å™¨ - åè°ƒæŸ¥è¯¢åˆ†æã€ä»»åŠ¡åˆ†è§£å’Œç­–ç•¥ç”Ÿæˆ"""
    
    def __init__(self, llm_enhancer: Optional[LLMEnhancer] = None, 
                 analyzer_type: str = "rule_based"):
        self.llm_enhancer = llm_enhancer
        self.analyzer_type = analyzer_type
        
        # æ ¹æ®é…ç½®é€‰æ‹©æŸ¥è¯¢åˆ†æå™¨
        self.query_analyzer = self._initialize_analyzer(analyzer_type, llm_enhancer)
        self.task_decomposer = TaskDecomposer(self.query_analyzer, llm_enhancer)
        self.strategy_generator = StrategyGenerator()
        
        logger.info(f"SearchPlanner åˆå§‹åŒ–å®Œæˆï¼Œåˆ†æå™¨ç±»å‹: {analyzer_type}")
    
    def set_dynamic_generation(self, enabled: bool):
        """è®¾ç½®æ˜¯å¦å¯ç”¨åŠ¨æ€æ­¥éª¤ç”Ÿæˆ"""
        self.task_decomposer.use_dynamic_generation = enabled
        logger.info(f"åŠ¨æ€æ­¥éª¤ç”Ÿæˆ: {'å¯ç”¨' if enabled else 'ç¦ç”¨'}")
    
    def _initialize_analyzer(self, analyzer_type: str, llm_enhancer: Optional[LLMEnhancer]):
        """åˆå§‹åŒ–æŸ¥è¯¢åˆ†æå™¨"""
        if analyzer_type == "advanced":
            try:
                from .advanced_query_analyzer import HybridQueryAnalyzer
                analyzer = HybridQueryAnalyzer(llm_enhancer)
                logger.info("âœ… ä½¿ç”¨é«˜çº§æ··åˆæŸ¥è¯¢åˆ†æå™¨")
                return analyzer
            except ImportError as e:
                logger.warning(f"âŒ é«˜çº§åˆ†æå™¨ä¸å¯ç”¨: {e}ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                return QueryAnalyzer(llm_enhancer)
            except Exception as e:
                logger.error(f"âŒ é«˜çº§åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                return QueryAnalyzer(llm_enhancer)
        elif analyzer_type == "bert":
            try:
                from .advanced_query_analyzer import BERTQueryAnalyzer
                analyzer = BERTQueryAnalyzer()
                if analyzer.is_available():
                    logger.info("âœ… ä½¿ç”¨BERTæŸ¥è¯¢åˆ†æå™¨")
                    return analyzer
                else:
                    logger.warning("âŒ BERTåˆ†æå™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                    return QueryAnalyzer(llm_enhancer)
            except ImportError:
                logger.warning("âŒ BERTåˆ†æå™¨ä¾èµ–ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                return QueryAnalyzer(llm_enhancer)
        elif analyzer_type == "llm":
            try:
                from .advanced_query_analyzer import LLMQueryAnalyzer
                analyzer = LLMQueryAnalyzer(llm_enhancer)
                if analyzer.is_available():
                    logger.info("âœ… ä½¿ç”¨LLMæŸ¥è¯¢åˆ†æå™¨")
                    return analyzer
                else:
                    logger.warning("âŒ LLMåˆ†æå™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                    return QueryAnalyzer(llm_enhancer)
            except ImportError:
                logger.warning("âŒ LLMåˆ†æå™¨ä¾èµ–ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æå™¨")
                return QueryAnalyzer(llm_enhancer)
        else:
            logger.info("âœ… ä½¿ç”¨åŸºç¡€è§„åˆ™æŸ¥è¯¢åˆ†æå™¨")
            return QueryAnalyzer(llm_enhancer)
    
    async def create_execution_plan(self, request: AgentSearchRequest) -> ExecutionPlan:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        logger.info(f"ğŸš€ å¼€å§‹åˆ›å»ºæ‰§è¡Œè®¡åˆ’: {request.query}")
        
        try:
            # 1. åˆ†ææŸ¥è¯¢
            logger.debug(f"æ­¥éª¤1: ä½¿ç”¨ {self.analyzer_type} åˆ†æå™¨åˆ†ææŸ¥è¯¢")
            analysis = await self._safe_analyze_query(request.query)
            
            # 2. ç”Ÿæˆç­–ç•¥
            logger.debug("æ­¥éª¤2: ç”Ÿæˆæ‰§è¡Œç­–ç•¥")
            strategy = self.strategy_generator.generate_strategy(request, analysis)
            
            # 3. åˆ†è§£ä»»åŠ¡
            logger.debug("æ­¥éª¤3: åˆ†è§£æ‰§è¡Œä»»åŠ¡")
            steps = await self.task_decomposer.decompose_task(request, analysis)
            
            # 4. éªŒè¯è®¡åˆ’
            logger.debug("æ­¥éª¤4: éªŒè¯æ‰§è¡Œè®¡åˆ’")
            self._validate_plan(steps)
            
            # 5. åˆ›å»ºæ‰§è¡Œè®¡åˆ’
            plan = ExecutionPlan(
                plan_id=f"plan_{uuid.uuid4().hex[:8]}",
                original_query=request.query,
                strategy=strategy,
                steps=steps,
                confidence_score=self._calculate_plan_confidence(analysis, steps)
            )
            
            logger.info(f"âœ… æ‰§è¡Œè®¡åˆ’åˆ›å»ºå®Œæˆ: {plan.plan_id}, ç­–ç•¥: {strategy.value}, æ­¥éª¤æ•°: {len(steps)}")
            return plan
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œè®¡åˆ’åˆ›å»ºå¤±è´¥: {e}")
            # åˆ›å»ºç®€å•çš„å›é€€è®¡åˆ’
            return self._create_fallback_plan(request)
    
    async def _safe_analyze_query(self, query: str):
        """å®‰å…¨çš„æŸ¥è¯¢åˆ†æï¼ŒåŒ…å«é”™è¯¯å¤„ç†"""
        try:
            return await self.query_analyzer.analyze_query(query)
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            # å›é€€åˆ°åŸºç¡€è§„åˆ™åˆ†æ
            basic_analyzer = QueryAnalyzer(self.llm_enhancer)
            return await basic_analyzer.analyze_query(query)
    
    def _validate_plan(self, steps: List[ExecutionStep]):
        """éªŒè¯æ‰§è¡Œè®¡åˆ’çš„æœ‰æ•ˆæ€§"""
        if not steps:
            raise ValueError("æ‰§è¡Œè®¡åˆ’ä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥æ­¥éª¤IDå”¯ä¸€æ€§
        step_ids = [step.step_id for step in steps]
        if len(step_ids) != len(set(step_ids)):
            raise ValueError("æ‰§è¡Œæ­¥éª¤IDå¿…é¡»å”¯ä¸€")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        for step in steps:
            if not step.query and step.step_type == StepType.SEARCH:
                raise ValueError(f"æœç´¢æ­¥éª¤ {step.step_id} ç¼ºå°‘æŸ¥è¯¢å†…å®¹")
    
    def _extract_analysis_summary(self, analysis) -> Dict[str, any]:
        """æå–åˆ†æç»“æœæ‘˜è¦"""
        if hasattr(analysis, 'query_type'):
            # é«˜çº§åˆ†æå™¨ç»“æœ
            return {
                "query_type": analysis.query_type,
                "complexity": analysis.complexity,
                "intent": analysis.intent,
                "confidence": getattr(analysis, 'confidence_scores', {}),
                "requires_multiple": analysis.requires_multiple_searches
            }
        else:
            # åŸºç¡€åˆ†æå™¨ç»“æœ
            return {
                "query_type": analysis.get("query_type", "unknown"),
                "complexity": analysis.get("complexity", "unknown"),
                "intent": analysis.get("intent", "unknown"),
                "requires_multiple": analysis.get("requires_multiple_searches", False)
            }
    
    def _create_fallback_plan(self, request: AgentSearchRequest) -> ExecutionPlan:
        """åˆ›å»ºå›é€€æ‰§è¡Œè®¡åˆ’"""
        logger.info("åˆ›å»ºç®€å•å›é€€æ‰§è¡Œè®¡åˆ’")
        
        fallback_step = ExecutionStep(
            step_id=f"fallback_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=f"ç®€å•æœç´¢: {request.query}",
            query=request.query,
            sources=request.sources,
            max_results=request.max_results_per_iteration,
            metadata={"is_fallback": True}
        )
        
        return ExecutionPlan(
            plan_id=f"fallback_{uuid.uuid4().hex[:8]}",
            original_query=request.query,
            strategy=PlanningStrategy.SIMPLE,
            steps=[fallback_step],
            confidence_score=0.5
        )
    
    def _calculate_plan_confidence(self, analysis, steps: List[ExecutionStep]) -> float:
        """è®¡ç®—è®¡åˆ’ç½®ä¿¡åº¦"""
        base_confidence = 0.7
        
        # æ ¹æ®åˆ†æå™¨ç±»å‹è°ƒæ•´åŸºç¡€ç½®ä¿¡åº¦
        if self.analyzer_type == "advanced":
            base_confidence = 0.8
        elif self.analyzer_type in ["bert", "llm"]:
            base_confidence = 0.75
        
        # æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è°ƒæ•´
        if hasattr(analysis, 'complexity'):
            complexity = analysis.complexity
        else:
            complexity = analysis.get("complexity", "simple")
            
        if complexity == "simple":
            base_confidence += 0.15
        elif complexity == "medium":
            base_confidence += 0.05
        elif complexity == "complex":
            base_confidence -= 0.1
        
        # æ ¹æ®æ­¥éª¤æ•°é‡è°ƒæ•´
        step_count = len(steps)
        if step_count == 1:
            base_confidence += 0.1
        elif step_count == 2:
            base_confidence += 0.05
        elif step_count > 4:
            base_confidence -= 0.15
        
        # æ ¹æ®åˆ†æå™¨ç½®ä¿¡åº¦è°ƒæ•´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(analysis, 'confidence_scores'):
            avg_confidence = sum(analysis.confidence_scores.values()) / len(analysis.confidence_scores)
            base_confidence = (base_confidence + avg_confidence) / 2
        
        # æ ¹æ®æ­¥éª¤ç±»å‹å¤šæ ·æ€§è°ƒæ•´
        step_types = set(step.step_type for step in steps)
        if len(step_types) > 1:
            base_confidence += 0.05  # å¤šæ ·åŒ–çš„æ­¥éª¤ç±»å‹æé«˜ç½®ä¿¡åº¦
        
        return min(max(base_confidence, 0.0), 1.0)
    
    def optimize_plan(self, plan: ExecutionPlan) -> ExecutionPlan:
        """ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’"""
        logger.info(f"ğŸ”§ å¼€å§‹ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’: {plan.plan_id}")
        
        try:
            # 1. å»é‡ç›¸ä¼¼æ­¥éª¤
            optimized_steps = self._deduplicate_steps(plan.steps)
            
            # 2. é‡æ–°æ’åºæ­¥éª¤
            optimized_steps = self._reorder_steps(optimized_steps, plan.strategy)
            
            # 3. åˆå¹¶å¯åˆå¹¶çš„æ­¥éª¤
            optimized_steps = self._merge_compatible_steps(optimized_steps)
            
            # 4. éªŒè¯ä¼˜åŒ–åçš„è®¡åˆ’
            self._validate_plan(optimized_steps)
            
            # åˆ›å»ºä¼˜åŒ–åçš„è®¡åˆ’
            optimized_plan = ExecutionPlan(
                plan_id=plan.plan_id,
                original_query=plan.original_query,
                strategy=plan.strategy,
                steps=optimized_steps,
                confidence_score=plan.confidence_score
            )
            
            logger.info(f"âœ… è®¡åˆ’ä¼˜åŒ–å®Œæˆ: {len(plan.steps)} -> {len(optimized_steps)} æ­¥éª¤")
            return optimized_plan
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡åˆ’ä¼˜åŒ–å¤±è´¥: {e}ï¼Œè¿”å›åŸè®¡åˆ’")
            return plan
    
    def _deduplicate_steps(self, steps: List[ExecutionStep]) -> List[ExecutionStep]:
        """å»é‡ç›¸ä¼¼çš„æ‰§è¡Œæ­¥éª¤"""
        unique_steps = []
        seen_queries = set()
        
        for step in steps:
            # ç®€å•çš„æŸ¥è¯¢å»é‡
            query_key = step.query.lower().strip()
            if query_key not in seen_queries:
                unique_steps.append(step)
                seen_queries.add(query_key)
            else:
                logger.debug(f"å»é‡æ­¥éª¤: {step.description}")
        
        return unique_steps
    
    def _reorder_steps(self, steps: List[ExecutionStep], strategy: PlanningStrategy) -> List[ExecutionStep]:
        """æ ¹æ®ç­–ç•¥é‡æ–°æ’åºæ­¥éª¤"""
        if strategy == PlanningStrategy.SIMPLE:
            # ç®€å•ç­–ç•¥ï¼šä¿æŒåŸé¡ºåº
            return steps
        elif strategy == PlanningStrategy.ITERATIVE:
            # è¿­ä»£ç­–ç•¥ï¼šæœç´¢æ­¥éª¤åœ¨å‰ï¼Œåˆ†ææ­¥éª¤åœ¨å
            search_steps = [s for s in steps if s.step_type == StepType.SEARCH]
            analyze_steps = [s for s in steps if s.step_type == StepType.ANALYZE]
            other_steps = [s for s in steps if s.step_type not in [StepType.SEARCH, StepType.ANALYZE]]
            return search_steps + other_steps + analyze_steps
        else:
            # å…¶ä»–ç­–ç•¥ï¼šä¿æŒåŸé¡ºåº
            return steps
    
    def _merge_compatible_steps(self, steps: List[ExecutionStep]) -> List[ExecutionStep]:
        """åˆå¹¶å…¼å®¹çš„æ‰§è¡Œæ­¥éª¤"""
        if len(steps) <= 1:
            return steps
        
        merged_steps = []
        i = 0
        
        while i < len(steps):
            current_step = steps[i]
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä¸ä¸‹ä¸€ä¸ªæ­¥éª¤åˆå¹¶
            if (i + 1 < len(steps) and 
                self._can_merge_steps(current_step, steps[i + 1])):
                
                merged_step = self._merge_two_steps(current_step, steps[i + 1])
                merged_steps.append(merged_step)
                i += 2  # è·³è¿‡ä¸‹ä¸€ä¸ªæ­¥éª¤
                logger.debug(f"åˆå¹¶æ­¥éª¤: {current_step.description} + {steps[i-1].description}")
            else:
                merged_steps.append(current_step)
                i += 1
        
        return merged_steps
    
    def _can_merge_steps(self, step1: ExecutionStep, step2: ExecutionStep) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæ­¥éª¤æ˜¯å¦å¯ä»¥åˆå¹¶"""
        # åªåˆå¹¶ç›¸åŒç±»å‹çš„æœç´¢æ­¥éª¤
        if (step1.step_type != StepType.SEARCH or 
            step2.step_type != StepType.SEARCH):
            return False
        
        # æ£€æŸ¥æŸ¥è¯¢ç›¸ä¼¼æ€§
        query1_words = set(step1.query.lower().split())
        query2_words = set(step2.query.lower().split())
        
        # å¦‚æœæœ‰è¶…è¿‡50%çš„è¯æ±‡é‡å ï¼Œè®¤ä¸ºå¯ä»¥åˆå¹¶
        overlap = len(query1_words & query2_words)
        total = len(query1_words | query2_words)
        
        return overlap / total > 0.5 if total > 0 else False
    
    def _merge_two_steps(self, step1: ExecutionStep, step2: ExecutionStep) -> ExecutionStep:
        """åˆå¹¶ä¸¤ä¸ªæ‰§è¡Œæ­¥éª¤"""
        merged_query = f"{step1.query} {step2.query}"
        merged_description = f"åˆå¹¶æœç´¢: {step1.query} & {step2.query}"
        
        return ExecutionStep(
            step_id=f"merged_{uuid.uuid4().hex[:8]}",
            step_type=StepType.SEARCH,
            description=merged_description,
            query=merged_query,
            sources=list(set(step1.sources + step2.sources)),
            max_results=max(step1.max_results, step2.max_results),
            metadata={
                "merged_from": [step1.step_id, step2.step_id],
                "original_queries": [step1.query, step2.query]
            }
        )
